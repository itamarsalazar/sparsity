{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84a1dab3f263e700"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def extract_attack_kwargs(train=False, eval=True):\n",
    "    args = None # delete this\n",
    "    l = []\n",
    "\n",
    "    def get_ord(ordstr):\n",
    "        if ordstr == 'inf':\n",
    "            return np.inf\n",
    "        else:\n",
    "            return int(ordstr)\n",
    "    if train:\n",
    "        train_kwargs = {\n",
    "            'out_dir': args.out_path,\n",
    "            'adv_train': int(args.adv_train),\n",
    "            'constraint': '2' if getattr(args, \"metrics_constraint\", None) is None else args.metrics_constraint,\n",
    "            'eps': args.eps_train,\n",
    "            'attack_lr': args.lr_train,\n",
    "            'attack_steps': args.iters_train,\n",
    "            'ord': get_ord(args.ord_train),\n",
    "            'constraint': args.ord_train,\n",
    "            'epochs': args.epochs,\n",
    "            'step_lr': args.epochs//args.lr_steps,\n",
    "            'lr': args.lr_opt,\n",
    "            'random_start': True\n",
    "        }\n",
    "        l.append(train_kwargs)\n",
    "    if eval:\n",
    "        attack_kwargs = {\n",
    "            \"eps\": 0.0356, # args.eps_eval,\n",
    "            \"nb_iter\": 20, # args.iters_eval,\n",
    "            \"eps_iter\": 0.01, # args.lr_eval,\n",
    "            'ord': get_ord('inf')\n",
    "        }\n",
    "        l.append(attack_kwargs)\n",
    "    return tuple(l) if len(l) > 1 else l[0]\n",
    "\n",
    "# Define the image transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T20:16:20.364110600Z",
     "start_time": "2024-07-22T20:16:18.459800600Z"
    }
   },
   "id": "3f3396c53aa7ec71"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "golden retriever 0.9293431639671326\n",
      "Labrador retriever 0.021033722907304764\n",
      "clumber 0.013683471828699112\n",
      "Great Pyrenees 0.009099332615733147\n",
      "otterhound 0.004993060603737831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u_imagenes\\.conda\\envs\\sparsity\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\u_imagenes\\.conda\\envs\\sparsity\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained ResNet18 model\n",
    "net = models.resnet18(pretrained=True)\n",
    "net.eval()\n",
    "\n",
    "# Load an image\n",
    "img_path = \"retriever-smiling-cropped.jpg\"\n",
    "input_image = Image.open(img_path)\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Create a mini-batch as expected by the model\n",
    "\n",
    "# Move the input to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_batch = input_batch.to(device)\n",
    "net.to(device)\n",
    "\n",
    "output = net(input_batch)\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "top_prob, top_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
    "with open(\"imagenet_classes.txt\") as f:\n",
    "    labels = [line.strip() for line in f.readlines()]\n",
    "\n",
    "for i in range(top_prob.size(0)):\n",
    "    print(labels[top_catid[i]], top_prob[i].item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T20:16:43.856718100Z",
     "start_time": "2024-07-22T20:16:43.676881Z"
    }
   },
   "id": "54898a0cc8e8e7a6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "attack_kwargs = extract_attack_kwargs()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T20:16:48.507236800Z",
     "start_time": "2024-07-22T20:16:48.496808800Z"
    }
   },
   "id": "f0a41515caa6a9e6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'eps': 0.0356, 'nb_iter': 20, 'eps_iter': 0.01, 'ord': inf}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_kwargs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T20:24:38.007470400Z",
     "start_time": "2024-07-22T20:24:37.997947900Z"
    }
   },
   "id": "8fb8bc0bd45adeb2"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-22T20:33:31.954561700Z",
     "start_time": "2024-07-22T20:33:31.944559100Z"
    }
   },
   "id": "187afa0978fca7b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e59068c1afac1e68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c862bc6c6c793b2c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5a3c1a30fa680db2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "60cc51a3a09ae16f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51661b16e4d33e56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "966c44dd30859ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b25b94b15f50d71b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a8cc0566b5a09e52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff9ff96a2fd94a80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9b7d0abd4095d100"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fb6981ebdd5e298c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
